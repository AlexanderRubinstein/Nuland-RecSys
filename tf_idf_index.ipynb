{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Alexander\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alexander\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "word_net_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# should be more sophisticated\n",
    "def pre_process(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text = re.sub(\"</?.*?>\",\" <> \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    text_words = nltk.word_tokenize(text)\n",
    "    lemmatized_text = \"\"\n",
    "    for word in text_words:\n",
    "        lemma = word_net_lemmatizer.lemmatize(word)\n",
    "        lemmatized_text += \" \" + lemma\n",
    "    text = lemmatized_text[1:] \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database creation/preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tasks_path = 'data/photo_youdo.json'\n",
    "df = pd.read_json(tasks_path, lines=True)\n",
    "df.rename(columns={'body': 'text'}, inplace=True)\n",
    "df['normalized'] = df['text'].apply(lambda x: pre_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Wedding photographer\\nNeed a photographer for ...</td>\n",
       "      <td>wedding photographer need a photographer for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Treatment youtube video\\nGood afternoon. It is...</td>\n",
       "      <td>treatment youtube video good afternoon it is n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Need a videographer\\nTo remove the backstage p...</td>\n",
       "      <td>need a videographer to remove the backstage ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Looking for a photographer for family photogra...</td>\n",
       "      <td>looking for a photographer for family photogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mount video 3.5 min\\nTotal duration 3 min 30 s...</td>\n",
       "      <td>mount video min total duration min sec there a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Subject photography\\nNeed to sell photos for t...</td>\n",
       "      <td>subject photography need to sell photo for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Photography\\nPhotographing models for my Insta...</td>\n",
       "      <td>photography photographing model for my instagr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Edit video\\nYou need to remove the logo to the...</td>\n",
       "      <td>edit video you need to remove the logo to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>To make a video review\\nYou need to make a vid...</td>\n",
       "      <td>to make a video review you need to make a vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Need to do a video\\nTo film the video</td>\n",
       "      <td>need to do a video to film the video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Wedding photographer\\nNeed a photographer for ...   \n",
       "1  Treatment youtube video\\nGood afternoon. It is...   \n",
       "2  Need a videographer\\nTo remove the backstage p...   \n",
       "3  Looking for a photographer for family photogra...   \n",
       "4  Mount video 3.5 min\\nTotal duration 3 min 30 s...   \n",
       "5  Subject photography\\nNeed to sell photos for t...   \n",
       "6  Photography\\nPhotographing models for my Insta...   \n",
       "7  Edit video\\nYou need to remove the logo to the...   \n",
       "8  To make a video review\\nYou need to make a vid...   \n",
       "9              Need to do a video\\nTo film the video   \n",
       "\n",
       "                                          normalized  \n",
       "0  wedding photographer need a photographer for a...  \n",
       "1  treatment youtube video good afternoon it is n...  \n",
       "2  need a videographer to remove the backstage ph...  \n",
       "3  looking for a photographer for family photogra...  \n",
       "4  mount video min total duration min sec there a...  \n",
       "5  subject photography need to sell photo for the...  \n",
       "6  photography photographing model for my instagr...  \n",
       "7  edit video you need to remove the logo to the ...  \n",
       "8  to make a video review you need to make a vide...  \n",
       "9               need to do a video to film the video  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TF-IDF based index + fetch tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysparnn.cluster_index as ci\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "class TasksIndex():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        nltk.download('stopwords')\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "        self.cv = CountVectorizer(max_df=0.85, stop_words=stop_words, max_features=10000)\n",
    "        docs = self.df['normalized'].tolist()\n",
    "        word_count_vector = self.cv.fit_transform(docs)\n",
    "    \n",
    "        self.tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "        self.tfidf_transformer.fit(word_count_vector)\n",
    "        features_vec = self.tfidf_transformer.transform(word_count_vector)\n",
    "        \n",
    "        self.index = ci.MultiClusterIndex(features_vec, list(range(len(docs))))\n",
    "        \n",
    "    def get_similar_tasks(self, message, k_tasks=10):\n",
    "        message = pre_process(message)\n",
    "        ftrs_vec = self.tfidf_transformer.transform(self.cv.transform([message]))\n",
    "        tasks = self.index.search(ftrs_vec, k=k_tasks, k_clusters=2, return_distance=0)[0]\n",
    "        tasks = [int(t) for t in tasks]\n",
    "    \n",
    "        tasks = self.df.iloc[tasks]['text'].tolist()\n",
    "    \n",
    "        return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alexander\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The photo of the dog\n",
      "To make beautiful photos of dogs\n",
      "\n",
      "Cat rental\n",
      "Good day! For the photo shoot in-Studio ( Moscow) required cat/cat not too large in size. To remove...\n",
      "\n",
      "Photography of interiors with the cat\n",
      "There is a small exhibition of furniture, 9 rooms. Need to take photos with the cat (or cats) in these interiors...\n",
      "\n",
      "Photo shoot of dogs on the street\n",
      "Photoshoot dogs\n",
      "\n",
      "Photo shoot with a dog\n",
      "I have a dog, I need a good staged photo of the dog and General. Perhaps the us will my...\n",
      "\n",
      "To make the video the dog was talking\n",
      "Need to make a video where the dog is removed and another video with the cat. ... so that they Move their mouth...\n",
      "\n",
      "Dog photos\n",
      "Need a photographer who can photograph dogs. Need photo 7 dogs for pristroystvo. Better on his car...\n",
      "\n",
      "Rent dogs for video shooting\n",
      "You need 2 dogs 1 breed Small and big dog to shoot for a blogger in instagram\n",
      "\n",
      "Need a chubby cat for a couple of photos\n",
      "I(we) the fat cat;) photo needed for the infopovod\n",
      "\n",
      "Photography\n",
      "Want a photo session love story, at some Studio\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\pysparnn\\matrix_distance.py:192: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  magnitude = 1.0 / (a_root_sum_square * self.matrix_root_sum_square)\n",
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\pysparnn\\matrix_distance.py:192: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  magnitude = 1.0 / (a_root_sum_square * self.matrix_root_sum_square)\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "index = TasksIndex(df)\n",
    "for t in index.get_similar_tasks('Help me! I love pets and I want to photo some dogs or cats'):\n",
    "    print(t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_COO(COO_matrix):\n",
    "    tuples = zip(COO_matrix.col, COO_matrix.data)\n",
    "    return sorted(tuples, key=lambda x:(x[1], x[0]), reverse=True)\n",
    "\n",
    "def topn(sorted_tuples, feature_names, topn):\n",
    "    feature_list = []\n",
    "    value_list = []\n",
    "    sorted_tuples = sorted_tuples[:topn]\n",
    "    for idx, value in sorted_tuples:\n",
    "        feature_list.append(feature_names[idx])\n",
    "        value_list.append(value)\n",
    "    results = {}\n",
    "    for idx in range(len(feature_list)):\n",
    "        results[feature_list[idx]] = value_list[idx]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wedding photographer need a photographer for a wedding february from to or hour charge the bride check the south west of moscow'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=cv.get_feature_names()\n",
    "sorted_tuples = sort_COO(tfidf_vector_0.tocoo())\n",
    "keywords = topn(sorted_tuples, feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "west 0.408918139910497\n",
      "wedding 0.39445350703255283\n",
      "charge 0.382671737159973\n",
      "south 0.36147329378014714\n",
      "check 0.31765348550026157\n",
      "february 0.3009251614760709\n",
      "bride 0.2997670593120834\n",
      "moscow 0.2146019947571679\n",
      "photographer 0.20567555262653536\n",
      "hour 0.15589967180316164\n"
     ]
    }
   ],
   "source": [
    "for k in keywords:\n",
    "    print(k, keywords[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
